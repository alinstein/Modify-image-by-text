{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "import datasets\n",
    "import img_text_composition_models\n",
    "import numpy as np\n",
    "from tensorboardX import SummaryWriter\n",
    "import test_retrieval\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "from tqdm import tqdm as tqdm\n",
    "from new_main import parse_opt, str2bool,load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import PIL\n",
    "import skimage.io\n",
    "split='train'\n",
    "path='../CSS'\n",
    "img_path = path + '/images/'\n",
    "img_path = img_path + ('/css_%s_%06d.png' % (split, int(3)))\n",
    "opt = parse_opt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datasets\n",
    "import tensorflow as tf\n",
    "\n",
    "# You'll generate plots of attention in order to see which parts of an image\n",
    "# our model focuses on during captioning\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scikit-learn includes many helpful utilities\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "class BaseDataset():\n",
    "  \"\"\"Base class for a dataset.\"\"\"\n",
    "\n",
    "  def __init__(self):\n",
    "    super(BaseDataset, self).__init__()\n",
    "    # image set\n",
    "    self.imgs = []\n",
    "    # tesr set\n",
    "    self.test_queries = []\n",
    "\n",
    "  def get_test_queries(self):\n",
    "    return self.test_queries\n",
    "\n",
    "  def get_all_texts(self):\n",
    "    raise NotImplementedError\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "  \n",
    "    return self.generate_random_query_target()\n",
    "  def load_data(self):\n",
    "        return self.generate_random_query_target()\n",
    "        \n",
    "\n",
    "  def generate_random_query_target(self):\n",
    "    raise NotImplementedError\n",
    "\n",
    "  def get_img(self, idx, raw_img=False):\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "class CSSDataset(BaseDataset):\n",
    "  \"\"\"CSS dataset.\"\"\"\n",
    "\n",
    "  def __init__(self, path, split='train', transform=None):\n",
    "    super(CSSDataset, self).__init__()\n",
    "    # location of images\n",
    "    path=str(path)\n",
    "    self.img_path = (path) + '/images/'\n",
    "    # transformation variable\n",
    "    self.transform = transform\n",
    "    self.split = split\n",
    "    # loading the numpy file\n",
    "    #changed in numpy format\n",
    "    self.data = np.load(path + '/css_toy_dataset_novel2_small.dup.npy',encoding='latin1',allow_pickle=True).item()\n",
    "    # selecting mods as per split (train of test)\n",
    "    # mod- modification, number of mods and object_img are different here\n",
    "    self.mods = self.data[self.split]['mods']\n",
    "    self.imgs = []\n",
    "    # retriving image and labels from the dataset\n",
    "    #change has_key to 'in' for python3\n",
    "    #Stores the objects and labels and caption in list - image\n",
    "    for objects in self.data[self.split]['objects_img']:\n",
    "      label = len(self.imgs)\n",
    "      if ('labels') in self.data[self.split]:\n",
    "                label = self.data[self.split]['labels'][label]\n",
    "\n",
    "      self.imgs += [{\n",
    "          'objects': objects,\n",
    "          'label': label,\n",
    "          'captions': [str(label)]\n",
    "          }]\n",
    "\n",
    "    self.imgid2modtarget = {}\n",
    "    for i in range(len(self.imgs)):\n",
    "      self.imgid2modtarget[i] = []\n",
    "    #Make combination of (from - to)\n",
    "    # it seems that for each object has more than one from-to elements\n",
    "    for i, mod in enumerate(self.mods):\n",
    "      for k in range(len(mod['from'])):\n",
    "        f = mod['from'][k]\n",
    "        t = mod['to'][k]\n",
    "        self.imgid2modtarget[f] += [(i, t)]\n",
    "\n",
    "    self.generate_test_queries_()\n",
    "\n",
    "  #This function combines 'from id' , 'to_id' and 'caption'\n",
    "  # {'source_img_id': 798, 'target_caption': '1000', 'mod': {'str': 'make middle-left large circle green'}}\n",
    "  def generate_test_queries_(self):\n",
    "    print(\"generate_test_queries_\")\n",
    "    test_queries = []\n",
    "    for mod in self.mods:\n",
    "      for i, j in zip(mod['from'], mod['to']):\n",
    "        test_queries += [{\n",
    "            'source_img_id': i,\n",
    "            'target_caption': self.imgs[j]['captions'][0],\n",
    "            'mod': {'str': mod['to_str']}\n",
    "        }]\n",
    "    self.test_queries = test_queries\n",
    "\n",
    "  def get_1st_training_query(self):\n",
    "   \n",
    "    #randomly selecting a mod, where i mod index \n",
    "    #j is index for selection of from and to image \n",
    "    i = np.random.randint(0, len(self.mods))\n",
    "    mod = self.mods[i]\n",
    "    j = np.random.randint(0, len(mod['from']))\n",
    "    self.last_from = mod['from'][j]\n",
    "    self.last_mod = [i]\n",
    "    return mod['from'][j], i, mod['to'][j]\n",
    "\n",
    "  def get_2nd_training_query(self):\n",
    "    #last_from is the varible stores the index of 'from' image from previous training query\n",
    "    modid, new_to = random.choice(self.imgid2modtarget[self.last_from])\n",
    "    #if modid is already used choose a new one\n",
    "    while modid in self.last_mod:\n",
    "      modid, new_to = random.choice(self.imgid2modtarget[self.last_from])\n",
    "    #Once this is used it is added into last_mod so that it won't used again\n",
    "    self.last_mod += [modid]\n",
    "    # mod = self.mods[modid]\n",
    "    return self.last_from, modid, new_to\n",
    "\n",
    "  def generate_random_query_target(self):\n",
    "    #when last_mod is not intialized get_1st_training_query is called\n",
    "    # once last_mod == 2, get_1st_training_query is called and last_mod is reset to [] empty\n",
    "    \n",
    "    try:\n",
    "      \n",
    "      if len(self.last_mod) < 2:\n",
    "        \n",
    "        img1id, modid, img2id = self.get_2nd_training_query()\n",
    "\n",
    "      else:\n",
    "        img1id, modid, img2id = self.get_1st_training_query()\n",
    "       \n",
    "        \n",
    "    except:\n",
    "      img1id, modid, img2id = self.get_1st_training_query()\n",
    "     \n",
    "\n",
    "    out = {}\n",
    "    out['source_img_id'] = img1id\n",
    "    #create the source image\n",
    "    #out['source_img_data'] = self.get_img(img1id)\n",
    "    out['target_img_id'] = img2id\n",
    "    #create the target image \n",
    "    #out['target_img_data'] = self.get_img(img2id)\n",
    "    #output image contain source image,target image and modification string and their corresponding ids\n",
    "    out['mod'] = {'id': modid, 'str': self.mods[modid]['to_str']}\n",
    "    return out\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.imgs)\n",
    "\n",
    "  def get_all_texts(self):\n",
    "    return [mod['to_str'] for mod in self.mods]\n",
    "\n",
    "  def get_img(self, idx, raw_img=False, get_2d=False):\n",
    "    \"\"\"Gets CSS images.\"\"\"\n",
    "    def generate_2d_image(objects):\n",
    "      img = np.ones((64, 64, 3))\n",
    "      colortext2values = {\n",
    "          'gray': [87, 87, 87],\n",
    "          'red': [244, 35, 35],\n",
    "          'blue': [42, 75, 215],\n",
    "          'green': [29, 205, 20],\n",
    "          'brown': [129, 74, 25],\n",
    "          'purple': [129, 38, 192],\n",
    "          'cyan': [41, 208, 208],\n",
    "          'yellow': [255, 238, 51]\n",
    "      }\n",
    "      for obj in objects:\n",
    "        s = 4.0\n",
    "        if obj['size'] == 'large':\n",
    "          s *= 2\n",
    "        c = [0, 0, 0]\n",
    "        for j in range(3):\n",
    "          c[j] = 1.0 * colortext2values[obj['color']][j] / 255.0\n",
    "        y = obj['pos'][0] * img.shape[0]\n",
    "        x = obj['pos'][1] * img.shape[1]\n",
    "        if obj['shape'] == 'rectangle':\n",
    "          img[int(y - s):int(y + s), int(x - s):int(x + s), :] = c\n",
    "        if obj['shape'] == 'circle':\n",
    "          for y0 in range(int(y - s), int(y + s) + 1):\n",
    "            x0 = x + (abs(y0 - y) - s)\n",
    "            x1 = 2 * x - x0\n",
    "            img[y0, int(x0):int(x1), :] = c\n",
    "        if obj['shape'] == 'triangle':\n",
    "          for y0 in range(int(y - s), int(y + s)):\n",
    "            x0 = x + (y0 - y + s) / 2\n",
    "            x1 = 2 * x - x0\n",
    "            x0, x1 = min(x0, x1), max(x0, x1)\n",
    "            img[y0, int(x0):int(x1), :] = c\n",
    "      return img\n",
    "\n",
    "    if self.img_path is None or get_2d:\n",
    "      img = generate_2d_image(self.imgs[idx]['objects'])\n",
    "    else:\n",
    "      img_path = self.img_path + ('/css_%s_%06d.png' % (self.split, int(idx)))\n",
    "      with open(img_path, 'rb') as f:\n",
    "        img = Image.open(f)\n",
    "        img = img.convert('RGB')\n",
    "        img = img.resize((224,224))\n",
    "        img = tf.keras.preprocessing.image.img_to_array(\n",
    "                img)\n",
    "        img = tf.image.per_image_standardization(img)\n",
    "\n",
    "    if raw_img:\n",
    "      return img\n",
    "    if self.transform:\n",
    "      img = self.transform(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../CSS/images//css_train_000003.png'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate_test_queries_\n"
     ]
    }
   ],
   "source": [
    "testset = CSSDataset(\n",
    "        path=opt.dataset_path,\n",
    "        split='test')\n",
    "xx = testset.get_test_queries()\n",
    "metadataT={}\n",
    "metadataT['mod']=[]\n",
    "metadataT['source_img_id']=[]\n",
    "metadataT['target_caption']=[]\n",
    "\n",
    "all_img_name_vector = []\n",
    "for x in (xx):\n",
    "    data=x\n",
    "    metadataT['target_caption'].append(data['target_caption'])\n",
    "    source_img_id=data['source_img_id']\n",
    "    metadataT['source_img_id'].append(('../CSS/images/css_%s_%06d.png' % (split, int(source_img_id))))\n",
    "    mod_str=data['mod']['str']\n",
    "    metadataT['mod'].append(mod_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_dataset=tf.data.Dataset.from_tensor_slices(metadataT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-1635a29e1d4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtests\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTIRGmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg_extractor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtext_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     tests += [(name + ' ' + metric_name, metric_value)\n\u001b[1;32m     12\u001b[0m               for metric_name, metric_value in t]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "# text_features=text_model(x['mod_str'])\n",
    "# imgS=img_extractor(x['source'])\n",
    "# imgT=img_extractor(x['target'])\n",
    "\n",
    "# C_feature=TIRGmodel(text_features, imgS)\n",
    "# loss=compute_soft_triplet_loss_(C_feature,imgT)\n",
    "\n",
    "tests = []\n",
    "for name, dataset in [ ('test', testset)]:\n",
    "    t = test(opt, TIRGmodel,img_extractor,text_model, dataset)\n",
    "    tests += [(name + ' ' + metric_name, metric_value)\n",
    "              for metric_name, metric_value in t]\n",
    "for metric_name, metric_value in tests:\n",
    "    \n",
    "    print ('    ', metric_name, round(metric_value, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for metric_name, metric_value in tests:\n",
    "    \n",
    "    print ('    ', metric_name, round(metric_value, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm as tqdm\n",
    "\n",
    "\n",
    "def test(opt, TIRG_m,IMG_m,Text_m, testset):\n",
    "  \"\"\"Tests a model over the given testset.\"\"\"\n",
    "  \n",
    "  test_queries = testset.get_test_queries()\n",
    "\n",
    "  all_imgs = []\n",
    "  all_captions = []\n",
    "  all_queries = []\n",
    "  all_target_captions = []\n",
    "  if test_queries:\n",
    " \n",
    "    # compute test query features\n",
    "    imgs = []\n",
    "    mods = []\n",
    "    #this loop appends the test_queries till it reaches the batch size \n",
    "    #and extract the features from the image and test using test model \n",
    "    for t in tqdm(test_queries):\n",
    "      #retriving the source image from id( or creating the image)\n",
    "      imgs += [testset.get_img(t['source_img_id'])]\n",
    "      mods += [t['mod']['str']]\n",
    "      # print(\"____________testing______________\")\n",
    "      # print(\"img___length    \",len(imgs))\n",
    "      # print(\"img___\\n    \",(mods))\n",
    "    \n",
    "\n",
    "      if len(imgs) >= opt.batch_size or t is test_queries[-1]:\n",
    "        # print(\"INside loop 1\")\n",
    "        if 'torch' not in str(type(imgs[0])):\n",
    "          imgs = [(d) for d in imgs]\n",
    "        imgs = tf.stack(imgs)\n",
    "        # imgs = torch.autograd.Variable(imgs).cuda()\n",
    "        mods = [t for t in mods]\n",
    "        img_f = IMG_m(imgs)\n",
    "        Text_f = Text_m(mods) \n",
    "        f= TIRG_m(img_f,Text_f)\n",
    "        #f = model.compose_img_text(imgs, mods).data.cpu().numpy()\n",
    "        all_queries += [f]\n",
    "        imgs = []\n",
    "        mods = []\n",
    "        # print(\"f    \",len(f))\n",
    "        # print(\"img___\\n    \",len(all_queries))\n",
    "        \n",
    "    all_queries = np.concatenate(all_queries)\n",
    "    all_target_captions = [t['target_caption'] for t in test_queries]\n",
    "   \n",
    "    \n",
    "    # compute all image features for target\n",
    "    imgs = []\n",
    "    for i in tqdm(range(len(testset.imgs))):\n",
    "      imgs += [testset.get_img(i)]\n",
    "      if len(imgs) >= opt.batch_size or i == len(testset.imgs) - 1:\n",
    "        if 'torch' not in str(type(imgs[0])):\n",
    "          imgs = [(d) for d in imgs]\n",
    "        \n",
    "        imgs = tf.stack(imgs)\n",
    "        #imgs = torch.autograd.Variable(imgs).cuda()\n",
    "\n",
    "        imgs = IMG_m(imgs)\n",
    "        #imgs = model.extract_img_feature(imgs).data.cpu().numpy()\n",
    "        all_imgs += [imgs]\n",
    "        imgs = []\n",
    "    all_imgs = np.concatenate(all_imgs)\n",
    "    all_captions = [img['captions'][0] for img in testset.imgs]\n",
    "\n",
    "  else:\n",
    "    print(\"Testing on Training data\")\n",
    "    # use training queries to approximate training retrieval performance\n",
    "    imgs0 = []\n",
    "    imgs = []\n",
    "    mods = []\n",
    "    for i in range(10000):\n",
    "      item = testset[i]\n",
    "      imgs += [item['source_img_data']]\n",
    "      mods += [item['mod']['str']]\n",
    "      if len(imgs) > opt.batch_size or i == 9999:\n",
    "        imgs = tf.stack(imgs)\n",
    "        #imgs = torch.autograd.Variable(imgs)\n",
    "        mods = [t for t in mods]\n",
    "        \n",
    "        img_f = IMG_m(imgs)\n",
    "        Text_f = Text_m(mods) \n",
    "        f= TIRG_m(img_f,Text_f)\n",
    "        \n",
    "        all_queries += [f]\n",
    "        imgs = []\n",
    "        mods = []\n",
    "      imgs0 += [item['target_img_data']]\n",
    "      if len(imgs0) > opt.batch_size or i == 9999:\n",
    "        imgs0 = tf.stack(imgs0)\n",
    "        imgs0 = IMG_m(imgs0)\n",
    "        #imgs0 = model.extract_img_feature(imgs0.cuda()).data.cpu().numpy()\n",
    "        \n",
    "\n",
    "        all_imgs += [imgs0]\n",
    "        imgs0 = []\n",
    "      all_captions += [item['target_caption']]\n",
    "      all_target_captions += [item['target_caption']]\n",
    "    all_imgs = np.concatenate(all_imgs)\n",
    "    all_queries = np.concatenate(all_queries)\n",
    "\n",
    "  # feature normalization\n",
    "  for i in range(all_queries.shape[0]):\n",
    "    all_queries[i, :] /= np.linalg.norm(all_queries[i, :])\n",
    "  for i in range(all_imgs.shape[0]):\n",
    "    all_imgs[i, :] /= np.linalg.norm(all_imgs[i, :])\n",
    "\n",
    "  # match test queries to target images, get nearest neighbors\n",
    "  sims = all_queries.dot(all_imgs.T)\n",
    "  #print(\"shape of sims\",sims.shape)\n",
    "  if test_queries:\n",
    "    for i, t in enumerate(test_queries):\n",
    "      sims[i, t['source_img_id']] = -10e10  # remove query image\n",
    "\n",
    "  #print(\"before\")    \n",
    "  nn_result = [np.argsort(-sims[i, :])[:110] for i in range(sims.shape[0])]\n",
    "\n",
    "  #print(\"after\")\n",
    "\n",
    "  #print(\"____nn_results\\n\")\n",
    "  #print(nn_result[0])\n",
    "  #print(len(nn_result))\n",
    "  # compute recalls\n",
    "  out = []\n",
    "  nn_result = [[all_captions[nn] for nn in nns] for nns in nn_result]\n",
    "  #print(\"__Again__nn_results\\n\")\n",
    "  #print(len(nn_result))\n",
    "  #print(nn_result[0])\n",
    "  for k in [1, 5, 10, 50, 100]:\n",
    "    #print(\"loop \",k)\n",
    "    r = 0.0\n",
    "    for i, nns in enumerate(nn_result):\n",
    "      if all_target_captions[i] in nns[:k]:\n",
    "        # if i==0:\n",
    "        #   print(\"all T captions\",all_target_captions[i])\n",
    "        #   print(\"all nns\",nns[:k])\n",
    "        #   print(\"location\", ((all_target_captions[i]  == nns[:k]).nonzero()))\n",
    "        r += 1\n",
    "    r /= len(nn_result)\n",
    "    out += [('recall_top' + str(k) + '_correct_composition', r)]\n",
    "  return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate_test_queries_\n"
     ]
    }
   ],
   "source": [
    "split='train'\n",
    "xx=CSSDataset(opt.dataset_path)\n",
    "metadata={}\n",
    "metadata['target_img_id']=[]\n",
    "metadata['source_img_id']=[]\n",
    "metadata['mod_id']=[]\n",
    "metadata['mod_str']=[]\n",
    "\n",
    "all_img_name_vector = []\n",
    "for x in range(len(xx)):\n",
    "    image_id = ('../CSS/images/css_%s_%06d.png' % (split, int(x)))\n",
    "    all_img_name_vector.append(image_id)\n",
    "    \n",
    "    data=xx.generate_random_query_target()\n",
    "    target_img_id=data['target_img_id']\n",
    "    metadata['target_img_id'].append(('../CSS/images/css_%s_%06d.png' % (split, int(target_img_id))))\n",
    "    source_img_id=data['source_img_id']\n",
    "    metadata['source_img_id'].append(('../CSS/images/css_%s_%06d.png' % (split, int(source_img_id))))\n",
    "    mod_id=data['mod']['id']\n",
    "    metadata['mod_id'].append(mod_id)\n",
    "    mod_str=data['mod']['str']\n",
    "    metadata['mod_str'].append(mod_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# trainset = CSSDataset(\n",
    "#         path=opt.dataset_path)\n",
    "# len(trainset.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# iter(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# len(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# len(metadata['mod_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_image(metadata):  \n",
    "    split='train'\n",
    "    target_img=metadata['target_img_id']\n",
    "    source_img=metadata['source_img_id']\n",
    "    mod_id=metadata['mod_id']\n",
    "    mod_str=metadata['mod_str']\n",
    " \n",
    "    img=tf.io.read_file(source_img, name=None)\n",
    "    s_img = tf.image.decode_png(img, channels=3)\n",
    "    #_img=tf.image.per_image_standardization(s_img)\n",
    "    s_img = tf.image.convert_image_dtype(s_img, tf.float32)\n",
    "    s_img=tf.image.resize(s_img, [224,224]) \n",
    "    img=tf.io.read_file(target_img, name=None)\n",
    "    #mg=tf.image.per_image_standardization(img)\n",
    "    t_img = tf.image.decode_png(img, channels=3)\n",
    "    t_img = tf.image.convert_image_dtype(t_img, tf.float32)\n",
    "    t_img=tf.image.resize(t_img, [224,224]) \n",
    "    return {'target':t_img,'source':s_img,'mod_id':mod_id,'mod_str':mod_str}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_dataset=tf.data.Dataset.from_tensor_slices(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_dataset = image_dataset.map(load_image).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "it = iter(image_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f62e599c4a8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x=next(it)\n",
    "plt.imshow(x['source'][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.93818414\n",
      "0.07314482\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f62e40ce748>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "print(np.max(x['target']))\n",
    "print(np.min(x['target']))\n",
    "plt.imshow(x['target'][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'make large purple object gray'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['mod_str'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "class ResnetIdentityBlock(tf.keras.Model):\n",
    "      def __init__(self):\n",
    "        self.embed_dim=2048    \n",
    "        super(ResnetIdentityBlock, self).__init__(name='')\n",
    "        #filters1, filters2, filters3 = filters\n",
    "        self.imgm=hub.KerasLayer(\"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4\",\n",
    "               trainable=False, arguments=dict(batch_norm_momentum=0.997))\n",
    "        self.bn2a  = tf.keras.layers.BatchNormalization()\n",
    "        #self.linear = tf.keras.layers.Dense(embed_dim, input_shape=(2048,))\n",
    "    \n",
    "\n",
    "      def call(self, input_tensor, training=False):\n",
    "        x = self.imgm(input_tensor)\n",
    "        x = self.bn2a(x, training=False)\n",
    "        return x\n",
    "\n",
    "\n",
    "class NormalizationLayer(tf.keras.Model):\n",
    "  \"\"\"Class for normalization layer.\"\"\"\n",
    "  def __init__(self, normalize_scale=4.0, learn_scale=True):\n",
    "    super(NormalizationLayer, self).__init__()\n",
    "    self.norm_s = float(normalize_scale)\n",
    "    if learn_scale:\n",
    "        self.norm_s = tf.Variable(self.norm_s, name='Normweights')\n",
    "\n",
    "  def call(self, x):\n",
    "\n",
    "    features = (self.norm_s * tf.math.l2_normalize(    x, axis=1, epsilon=1e-12 ))\n",
    "\n",
    "    #features = self.norm_s * x / torch.norm(x, dim=1, keepdim=True).expand_as(x)\n",
    "    return features\n",
    "\n",
    "\n",
    "# class MyDenseLayer(tf.keras.layers.Layer):\n",
    "#   def __init__(self, num_outputs):\n",
    "#     super(MyDenseLayer, self).__init__()\n",
    "#     self.num_outputs = num_outputs\n",
    "\n",
    "#   def build(self, input_shape):\n",
    "#     self.kernel = self.add_weight(\"kernel\",\n",
    "#                                     shape=[int(input_shape[-1]),\n",
    "#                                            self.num_outputs])\n",
    "\n",
    "#   def call(self, input):\n",
    "#     return tf.matmul(input, self.kernel)\n",
    "\n",
    "my_seq = tf.keras.Sequential([ResnetIdentityBlock(),NormalizationLayer()])\n",
    "my_seq2 = tf.keras.Sequential([ResnetIdentityBlock()])\n",
    "\n",
    "#layer = MyDenseLayer(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 2048)\n",
      "(32, 2048)\n"
     ]
    }
   ],
   "source": [
    "y=my_seq(x['target']) \n",
    "y2=my_seq2(x['target']) \n",
    "print(y2.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 21.88695\n",
      "0.0 2.1916814\n"
     ]
    }
   ],
   "source": [
    "#print(y.shape)\n",
    "print(np.min(y2),np.max(y2))\n",
    "print(np.min(y),np.max(y))\n",
    "#tf.Variable([1.0, 10.0, 1.0, 1.0], tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "class SimpleVocab(object):\n",
    "\n",
    "  def __init__(self):\n",
    "    super(SimpleVocab, self).__init__()\n",
    "    self.word2id = {}\n",
    "    self.wordcount = {}\n",
    "    self.word2id['<UNK>'] = 0\n",
    "    self.wordcount['<UNK>'] = 9e9\n",
    "\n",
    "  def tokenize_text(self, text):\n",
    "    text = text\n",
    "    tokens = str(text).lower().translate(str.maketrans('','',string.punctuation)).strip().split()\n",
    "    return tokens\n",
    "\n",
    "  def add_text_to_vocab(self, text):\n",
    "    tokens = self.tokenize_text(text)\n",
    "    \n",
    "    for token in tokens:\n",
    "      if token not in self.word2id:\n",
    "        self.word2id[token] = len(self.word2id)\n",
    "        self.wordcount[token] = 0\n",
    "      self.wordcount[token] += 1\n",
    "\n",
    "    \n",
    "\n",
    "  def threshold_rare_words(self, wordcount_threshold=5):\n",
    "    for w in self.word2id:\n",
    "      if self.wordcount[w] < wordcount_threshold:\n",
    "        self.word2id[w] = 0\n",
    "\n",
    "  def encode_text(self, text):\n",
    "    tokens = self.tokenize_text(text)\n",
    "    x = [self.word2id.get(t, 0) for t in tokens]\n",
    "    return x\n",
    "\n",
    "  def get_size(self):\n",
    "    return len(self.word2id)\n",
    "\n",
    "\n",
    "class TextLSTMModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self,\n",
    "               texts_to_build_vocab,\n",
    "               word_embed_dim=1028,\n",
    "               lstm_hidden_dim=1028):\n",
    "\n",
    "    super(TextLSTMModel, self).__init__()\n",
    "\n",
    "    self.vocab = SimpleVocab()\n",
    "    for text in texts_to_build_vocab:\n",
    "      self.vocab.add_text_to_vocab(text)\n",
    "    vocab_size = self.vocab.get_size()\n",
    "\n",
    "    self.word_embed_dim = word_embed_dim\n",
    "    self.lstm_hidden_dim = lstm_hidden_dim\n",
    "    #self.embedding_layer = torch.nn.Embedding(vocab_size, word_embed_dim)\n",
    "    self.embedding_layer = layers.Embedding(input_dim=vocab_size, output_dim=word_embed_dim)\n",
    "    #GRU_implementaiontf.keras.layers.RNN( \n",
    "    self.gru=tf.keras.layers.GRU(lstm_hidden_dim) \n",
    "    #self.gru = layers.GRU(word_embed_dim, lstm_hidden_dim)\n",
    "    \n",
    "    # self.lstm = torch.nn.LSTM(word_embed_dim, lstm_hidden_dim)\n",
    "    #     self.fc_output = torch.nn.Sequential(\n",
    "    #         torch.nn.Dropout(p=0.1),\n",
    "    #         torch.nn.Linear(lstm_hidden_dim, lstm_hidden_dim),\n",
    "    #     )\n",
    "    #self.fc_output = tf.keras.Sequential([tf.keras.layers.Dropout(.1),\n",
    "                                         # tf.keras.layers.Dense(lstm_hidden_dim,lstm_hidden_dim)])\n",
    "    self.fc_output = tf.keras.Sequential([tf.keras.layers.Dropout(.1), \n",
    "                                          tf.keras.layers.Dense(lstm_hidden_dim, input_shape=(lstm_hidden_dim,))])\n",
    "\n",
    "  def call(self, x):\n",
    "\n",
    "    # to tensor\n",
    "#     lengths = [len(t) for t in texts]\n",
    "#     itexts = tf.tensor(tf.zeros([np.max(lengths), len(texts)]))\n",
    "#     #itexts = torch.zeros((np.max(lengths), len(texts))).long()\n",
    "#     for i in range(len(texts)):\n",
    "#       itexts[:lengths[i], i] = tf.Variable(texts[i])\n",
    "\n",
    "    # embed words\n",
    "#     if torch.cuda.is_available():\n",
    "#       itexts = torch.autograd.Variable(itexts).cuda()\n",
    "    x = [self.vocab.encode_text(text) for text in x]\n",
    "    lengths = [len(t) for t in x]\n",
    "    itexts = np.zeros((len(x),np.max(lengths)))\n",
    "    for i in range(len(x)):\n",
    "        #print(i)\n",
    "        itexts[ i,:lengths[i]]=(x[i])\n",
    "        #print(\"x\",x[i])\n",
    "        #print(itexts)\n",
    "    \n",
    "    #itexts=self.vocab.encode_text(texts)\n",
    "    #print(itexts)\n",
    "    \n",
    "    etexts = self.embedding_layer(itexts)\n",
    "\n",
    "    # lstm\n",
    "    lstm_output = self.forward_lstm_(etexts)\n",
    "    \n",
    "    # get last output (using length)\n",
    "#     text_features = []\n",
    "#     for i in range(len(x)):\n",
    "#       text_features.append(lstm_output[lengths[i] - 1, i, :])\n",
    "    # output\n",
    "    #text_features = torch.stack(text_features)\n",
    "    text_features = self.fc_output(lstm_output)\n",
    "    return text_features\n",
    "\n",
    "  def forward_lstm_(self, etexts):\n",
    "    batch_size = etexts.shape[1]\n",
    "    \n",
    "    #GRU implemention\n",
    "    #first_hidden = (torch.zeros(1, batch_size, self.lstm_hidden_dim))\n",
    "    #first_hidden = (first_hidden[0].cuda(), first_hidden[1].cuda())\n",
    "#     if torch.cuda.is_available(): \n",
    "#       first_hidden = (first_hidden.cuda())\n",
    "#     else :\n",
    "#       first_hidden = (first_hidden)\n",
    "\n",
    "    lstm_output = self.gru(etexts)\n",
    "    # print(\"GRU CALLED\")\n",
    "\n",
    "    return lstm_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x=next(it)\n",
    "text=x['mod_str']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "texts=[t for t in xx.get_all_texts()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embed_dim=1280\n",
    "text_model = TextLSTMModel(\n",
    "                    texts_to_build_vocab=texts,\n",
    "                    word_embed_dim=embed_dim,\n",
    "                    lstm_hidden_dim=embed_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 1280), dtype=float32, numpy=\n",
       "array([[-0.0027497 ,  0.01996926,  0.03127627, ..., -0.02119767,\n",
       "         0.01139197,  0.02637821],\n",
       "       [-0.0082362 ,  0.02282355,  0.03349533, ..., -0.01982735,\n",
       "         0.0121906 ,  0.02370686],\n",
       "       [-0.00267662,  0.01963019,  0.0362697 , ..., -0.02234709,\n",
       "         0.01390666,  0.03012392],\n",
       "       ...,\n",
       "       [-0.00442451,  0.01533274,  0.02883581, ..., -0.01620508,\n",
       "         0.00500441,  0.02572719],\n",
       "       [-0.00598551,  0.01965377,  0.03145843, ..., -0.02283865,\n",
       "         0.01391649,  0.02656338],\n",
       "       [-0.00526672,  0.01747405,  0.03112719, ..., -0.02331364,\n",
       "         0.01334436,  0.02593824]], dtype=float32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_model(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_lstm_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  35840     \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    multiple                  9838080   \n",
      "_________________________________________________________________\n",
      "sequential_3 (Sequential)    multiple                  1639680   \n",
      "=================================================================\n",
      "Total params: 11,513,600\n",
      "Trainable params: 11,513,600\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "text_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_feat=text_model(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 1280])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# class Concat(tf.keras.Model):\n",
    "#   \"\"\"Concatenation model.\"\"\"\n",
    "\n",
    "#   def __init__(self, texts, embed_dim):\n",
    "#     super(Concat, self).__init__(texts, embed_dim)    \n",
    "    \n",
    "#     class Composer(tf.keras.Model):\n",
    "#         \"\"\"Inner composer class.\"\"\"\n",
    "#         def __init__(self):\n",
    "#                 super(Composer, self).__init__()\n",
    "\n",
    "#                 self.b1= tf.keras.layers.BatchNormalization(axis=-1)\n",
    "#                 self.D1= tf.keras.layers.Dense(2 * embed_dim, input_shape=(2 * embed_dim,))\n",
    "#                 self.b2= tf.keras.layers.BatchNormalization(axis=-1)\n",
    "#                 self.Drop= tf.keras.layers.Dropout(0.1)\n",
    "#                 self.D2=   tf.keras.layers.Dense(2 * embed_dim, input_shape=(2 * embed_dim,))\n",
    "\n",
    "#         def forward(self, x):\n",
    "#                 f = tf.concat(c, axis=1, name='concat')\n",
    "#                 f = self.b1(f)\n",
    "#                 f = tf.nn.relu(f)\n",
    "#                 f = self.D1(f)\n",
    "#                 f = self.b2(f)\n",
    "#                 f = tf.nn.relu(f)\n",
    "#                 f = self.Drop(f)\n",
    "#                 f = self.D2(f)\n",
    "#                 return f\n",
    "\n",
    "#     self.composer = Composer()\n",
    "\n",
    "#     def compose_img_text(self, imgs, texts):\n",
    "#             img_features = self.extract_img_feature(imgs)\n",
    "#             text_features = self.extract_text_feature(texts)\n",
    "#             return self.compose_img_text_features(img_features, text_features)\n",
    "\n",
    "#     def compose_img_text_features(self, img_features, text_features):\n",
    "#             return self.composer((img_features, text_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class Composer(tf.keras.Model):\n",
    "#         \"\"\"Inner composer class.\"\"\"\n",
    "#         def __init__(self):\n",
    "#                 super(Composer, self).__init__()\n",
    "\n",
    "#                 self.b1= tf.keras.layers.BatchNormalization(axis=-1)\n",
    "#                 self.D1= tf.keras.layers.Dense(2 * embed_dim, input_shape=(2 * embed_dim,))\n",
    "#                 self.b2= tf.keras.layers.BatchNormalization(axis=-1)\n",
    "#                 self.Drop= tf.keras.layers.Dropout(0.1)\n",
    "#                 self.D2=   tf.keras.layers.Dense( embed_dim, input_shape=(2 * embed_dim,))\n",
    "\n",
    "#         def call(self, x,y):\n",
    "#                 f = tf.concat([x,y], axis=1, name='concat')\n",
    "\n",
    "#                 f = self.b1(f)\n",
    "#                 f = tf.nn.relu(f)\n",
    "#                 f = self.D1(f)\n",
    "#                 f = self.b2(f)\n",
    "#                 f = tf.nn.relu(f)\n",
    "#                 f = self.Drop(f)\n",
    "#                 f = self.D2(f)\n",
    "#                 return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMG_SHAPE = (224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_model =tf.keras.applications.ResNet50(\n",
    "    include_top=False, weights='imagenet', input_shape=IMG_SHAPE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "IMG_SHAPE = (224, 224, 3)\n",
    "base_model =tf.keras.applications.ResNet50(\n",
    "    include_top=False, weights='imagenet', input_shape=IMG_SHAPE)\n",
    "base_model.trainable = False\n",
    "img_extractor = tf.keras.Sequential([\n",
    "  base_model,\n",
    "  tf.keras.layers.BatchNormalization()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 7, 7, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 7, 7, 2048)        8192      \n",
      "=================================================================\n",
      "Total params: 23,595,904\n",
      "Trainable params: 4,096\n",
      "Non-trainable params: 23,591,808\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "img_extractor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'batch_normalization_2/gamma:0' shape=(2048,) dtype=float32, numpy=array([1., 1., 1., ..., 1., 1., 1.], dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_2/beta:0' shape=(2048,) dtype=float32, numpy=array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_extractor.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ConCatModule(tf.keras.Model):\n",
    "\n",
    "  def __init__(self):\n",
    "    super(ConCatModule, self).__init__()\n",
    "\n",
    "  def call(self, x):\n",
    "    x = tf.concat(x, axis=1)\n",
    "    return x\n",
    "\n",
    "\n",
    "class TIRG(tf.keras.Model):\n",
    "  def __init__(self, texts, embed_dim):\n",
    "        super(TIRG, self).__init__().__init__(name='')\n",
    "\n",
    "        self.a = tf.Variable(([0.1, 0.2, 0.7, 1.0]))\n",
    "        self.gated_feature_composer = tf.keras.models.Sequential([\n",
    "                        ConCatModule(), \n",
    "                        tf.keras.layers.BatchNormalization(axis=-1), \n",
    "                        tf.keras.layers.Activation('relu'),\n",
    "                        tf.keras.layers.Dense(embed_dim, input_shape=(2 * embed_dim,)),\n",
    "                        ])\n",
    "\n",
    "        self.res_info_composer = tf.keras.models.Sequential([\n",
    "                        ConCatModule(), \n",
    "                        tf.keras.layers.BatchNormalization(axis=-1), \n",
    "                        tf.keras.layers.Activation('relu'),\n",
    "                        tf.keras.layers.Dense(2 * embed_dim, input_shape=(2 * embed_dim,)),\n",
    "                        tf.keras.layers.Activation('relu'),\n",
    "                        tf.keras.layers.Activation('softmax'),\n",
    "                        tf.keras.layers.Dense( embed_dim, input_shape=(2 * embed_dim,))\n",
    "                        ])         \n",
    "\n",
    "                        \n",
    "#         self.text_model = tf.keras.Sequential(TextLSTMModel(texts_to_build_vocab=texts,word_embed_dim=embed_dim,\n",
    "#                         lstm_hidden_dim=embed_dim)   ) \n",
    "\n",
    "#         self.Img_feature = tf.keras.Sequential([ResnetIdentityBlock()])\n",
    "\n",
    "#   def extract_img(self,img):\n",
    "#         return self.Img_feature(img)\n",
    "\n",
    "  def call(self, img_features, text_features):   \n",
    "        \n",
    "    \n",
    "    f1 = self.gated_feature_composer((img_features, text_features))\n",
    "    f2 = self.res_info_composer((img_features, text_features))\n",
    "    f = tf.keras.activations.sigmoid(f1) * img_features * self.a[0] + f2 * self.a[1]+img_features * self.a[2] \n",
    "    return f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compose=Composer()\n",
    "# def compose_img_text(imgs, texts):\n",
    "#     img_features=my_seq2(imgs)\n",
    "#     text_features=text_model.forward_encoded_texts(texts)\n",
    "    \n",
    "#     return compose(img_features, text_features)\n",
    "\n",
    "# # compose=Composer()\n",
    "# # composite=compose(y,text_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TIRGmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# it = iter(image_dataset)\n",
    "# x=next(it)\n",
    "# com=TIRGmodel(x['source'],x['mod_str'])\n",
    "# target=my_seq2(x['target'])\n",
    "# source=my_seq2(x['source'])\n",
    "# print(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# it = iter(image_dataset)\n",
    "# x=next(it)\n",
    "# com=compose_img_text(x['target'],x['mod_str'])\n",
    "# target=my_seq2(x['target'])\n",
    "# source=my_seq2(x['source'])\n",
    "# print(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# np.sum(target-source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "class ConCatModule(torch.nn.Module):\n",
    "\n",
    "  def __init__(self):\n",
    "    super(ConCatModule, self).__init__()\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = torch.cat(x, dim=1)\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ImgTextCompositionBase(torch.nn.Module):\n",
    "  \"\"\"Base class for image + text composition.\"\"\"\n",
    "\n",
    "  def __init__(self):\n",
    "    super(ImgTextCompositionBase, self).__init__()\n",
    "    self.normalization_layer = torch_functions.NormalizationLayer(\n",
    "        normalize_scale=4.0, learn_scale=True)\n",
    "    self.soft_triplet_loss = torch_functions.TripletLoss()\n",
    "\n",
    "  def extract_img_feature(self, imgs):\n",
    "    raise NotImplementedError\n",
    "\n",
    "  def extract_text_feature(self, texts):\n",
    "    raise NotImplementedError\n",
    "\n",
    "  def compose_img_text(self, imgs, texts):\n",
    "    raise NotImplementedError\n",
    "\n",
    "  def compute_loss(self,\n",
    "                   imgs_query,\n",
    "                   modification_texts,\n",
    "                   imgs_target,\n",
    "                   soft_triplet_loss=True):\n",
    "   \n",
    "    mod_img1 = self.compose_img_text(imgs_query, modification_texts)\n",
    "    mod_img1 = self.normalization_layer(mod_img1)\n",
    "    \n",
    "    img2 = self.extract_img_feature(imgs_target)\n",
    "    img2 = self.normalization_layer(img2)\n",
    "    \n",
    "    assert (mod_img1.shape[0] == img2.shape[0] and\n",
    "            mod_img1.shape[1] == img2.shape[1])\n",
    "    if soft_triplet_loss:\n",
    "      \n",
    "      return self.compute_soft_triplet_loss_(mod_img1, img2)\n",
    "    else:\n",
    "      return self.compute_batch_based_classification_loss_(mod_img1, img2)\n",
    "\n",
    "\n",
    "  def compute_soft_triplet_loss_(self, mod_img1, img2):\n",
    "    triplets = []\n",
    "    labels = list(range(mod_img1.shape[0])) + list(range(img2.shape[0]))\n",
    "    for i in range(len(labels)):\n",
    "      triplets_i = []\n",
    "      for j in range(len(labels)):\n",
    "        if labels[i] == labels[j] and i != j:\n",
    "          for k in range(len(labels)):\n",
    "            if labels[i] != labels[k]:\n",
    "              triplets_i.append([i, j, k])\n",
    "      np.random.shuffle(triplets_i)\n",
    "      triplets += triplets_i[:3]\n",
    "    assert (triplets and len(triplets) < 2000)\n",
    "    #print(self.soft_triplet_loss(torch.cat([mod_img1, img2]), triplets))\n",
    "    return self.soft_triplet_loss(torch.cat([mod_img1, img2]), triplets)\n",
    "\n",
    "  def compute_batch_based_classification_loss_(self, mod_img1, img2):\n",
    "    x = torch.mm(mod_img1, img2.transpose(0, 1))\n",
    "    labels = torch.tensor(range(x.shape[0])).long()\n",
    "    labels = torch.autograd.Variable(labels).cuda()\n",
    "    return F.cross_entropy(x, labels)\n",
    "\n",
    "\n",
    "class ImgEncoderTextEncoderBase(ImgTextCompositionBase):\n",
    "  \"\"\"Base class for image and text encoder.\"\"\"\n",
    "\n",
    "  def __init__(self, texts, embed_dim):\n",
    "    super(ImgEncoderTextEncoderBase, self).__init__()\n",
    "\n",
    "    # img model\n",
    "    img_model = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "    class GlobalAvgPool2d(torch.nn.Module):\n",
    "\n",
    "      def forward(self, x):\n",
    "        return F.adaptive_avg_pool2d(x, (1, 1))\n",
    "\n",
    "    img_model.avgpool = GlobalAvgPool2d()\n",
    "    img_model.fc = torch.nn.Sequential(torch.nn.Linear(512, embed_dim))\n",
    "    self.img_model = img_model\n",
    "\n",
    "    # text model\n",
    "    self.text_model = text_model.TextLSTMModel(\n",
    "        texts_to_build_vocab=texts,\n",
    "        word_embed_dim=embed_dim,\n",
    "        lstm_hidden_dim=embed_dim)\n",
    "\n",
    "  def extract_img_feature(self, imgs):\n",
    "    return self.img_model(imgs)\n",
    "\n",
    "  def extract_text_feature(self, texts):\n",
    "    return self.text_model(texts)\n",
    "\n",
    "\n",
    "class TIRGRevGrad(ImgEncoderTextEncoderBase):\n",
    "    def __init__(self, texts, embed_dim):\n",
    "        super().__init__(texts, embed_dim)\n",
    "        # self.feature_extractor = nn.Sequential(      \n",
    "        # )\n",
    "        self.num_cnn_features = embed_dim\n",
    "        self.normalization_layer = torch_functions.NormalizationLayer(\n",
    "            normalize_scale=4.0, learn_scale=True)\n",
    "        self.soft_triplet_loss = torch_functions.TripletLoss()\n",
    "        \n",
    "        self.a = torch.nn.Parameter(torch.tensor([1.0, 10.0, 1.0, 1.0]))\n",
    "\n",
    "        self.gated_feature_composer = torch.nn.Sequential(\n",
    "             ConCatModule(), torch.nn.BatchNorm1d(2 * embed_dim),\n",
    "             torch.nn.ReLU(),torch.nn.Linear(2 * embed_dim, embed_dim)\n",
    "        )\n",
    "\n",
    "        img_model = torchvision.models.resnet18(pretrained=True)\n",
    "        class GlobalAvgPool2d(torch.nn.Module):\n",
    "           def forward(self, x):\n",
    "              return F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        img_model.avgpool = GlobalAvgPool2d()\n",
    "        img_model.fc = torch.nn.Sequential(torch.nn.Linear(512, embed_dim))\n",
    "        self.img_model = img_model\n",
    "\n",
    "        # text model\n",
    "        self.text_model = text_model.TextLSTMModel(\n",
    "                    texts_to_build_vocab=texts,\n",
    "                    word_embed_dim=embed_dim,\n",
    "                    lstm_hidden_dim=embed_dim)\n",
    "        \n",
    "        self.res_info_composer = torch.nn.Sequential(\n",
    "            ConCatModule(), torch.nn.BatchNorm1d(2 * embed_dim),\n",
    "            torch.nn.ReLU(), torch.nn.Linear(2 * embed_dim, 2 * embed_dim),\n",
    "            torch.nn.ReLU(), torch.nn.Linear(2 * embed_dim, embed_dim)\n",
    "        )\n",
    "\n",
    "        self.domain_classifier = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.num_cnn_features, 100),\n",
    "            torch.nn.BatchNorm1d(100), torch.nn.ReLU(True),\n",
    "            torch.nn.Linear(100, 2),\n",
    "            torch.nn.LogSoftmax(dim=1),)\n",
    "\n",
    "    def compute_loss(self,imgs_query,modification_texts,imgs_target,soft_triplet_loss=True):\n",
    "            mod_img1 = self.compose_img_text(imgs_query, modification_texts)\n",
    "            mod_img1 = self.normalization_layer(mod_img1)\n",
    "            img2 = self.extract_img_feature(imgs_target)\n",
    "            img2 = self.normalization_layer(img2)\n",
    "            assert (mod_img1.shape[0] == img2.shape[0] and\n",
    "                    mod_img1.shape[1] == img2.shape[1])\n",
    "            return self.compute_soft_triplet_loss_(mod_img1, img2)\n",
    "\n",
    "    def compute_soft_triplet_loss_(self, mod_img1, img2):\n",
    "            triplets = []\n",
    "            labels = list(range(mod_img1.shape[0])) + list(range(img2.shape[0]))\n",
    "            for i in range(len(labels)):\n",
    "              triplets_i = []\n",
    "              for j in range(len(labels)):\n",
    "                if labels[i] == labels[j] and i != j:\n",
    "                  for k in range(len(labels)):\n",
    "                    if labels[i] != labels[k]:\n",
    "                      triplets_i.append([i, j, k])\n",
    "              np.random.shuffle(triplets_i)\n",
    "              triplets += triplets_i[:3]\n",
    "            assert (triplets and len(triplets) < 2000)\n",
    "            return self.soft_triplet_loss(torch.cat([mod_img1, img2]), triplets)\n",
    "\n",
    "\n",
    "    def compose_img_text(self, imgs, texts):\n",
    "        img_features = self.extract_img_feature(imgs)\n",
    "        text_features = self.extract_text_feature(texts)\n",
    "        return self.compose_img_text_features(img_features, text_features)\n",
    "\n",
    "    def compose_img_text_features(self, img_features, text_features):\n",
    "        f1 = self.gated_feature_composer((img_features, text_features))\n",
    "        f2 = self.res_info_composer((img_features, text_features))\n",
    "        f = torch.sigmoid(f1) * img_features * self.a[0] + f2 * self.a[1]\n",
    "        return f\n",
    "\n",
    "    def extract_img_feature(self, imgs):\n",
    "             return self.img_model(imgs)\n",
    "\n",
    "    def extract_text_feature(self, texts):\n",
    "             return self.text_model(texts)          \n",
    "            \n",
    "    def forward(self, imgs_query, modification_texts,img2, grl_lambda=1.0):\n",
    "        # Handle single-channel input by expanding (repeating) the singleton dimention\n",
    "        # x = x.expand(x.data.shape[0], 3, image_size, image_size)\n",
    "\n",
    "        loss = self.compute_loss(imgs_query, modification_texts,img2, soft_triplet_loss=True)\n",
    "        features= self.compose_img_text(imgs_query, modification_texts)\n",
    "        #features = features.view(-1, self.num_cnn_features)\n",
    "        #print(features.shape)\n",
    "        features_grl = GradientReversalFn.apply(features, grl_lambda)\n",
    "        # class_pred = self.class_classifier(features)        # classify on regular features\n",
    "        domain_pred = self.domain_classifier(features_grl)  # classify on features after GRL\n",
    "        return domain_pred , loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = img_text_composition_models.TIRGRevGrad(texts, embed_dim=opt.embed_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"tf.Tensor(b'make top-center small object red', shape=(), dtype=string)\", \"tf.Tensor(b'make middle-right gray rectangle blue', shape=(), dtype=string)\", \"tf.Tensor(b'make middle-right brown circle yellow', shape=(), dtype=string)\", \"tf.Tensor(b'make top-right blue object red', shape=(), dtype=string)\", \"tf.Tensor(b'add yellow circle to bottom-right', shape=(), dtype=string)\", \"tf.Tensor(b'add small yellow triangle to middle-left', shape=(), dtype=string)\", \"tf.Tensor(b'make bottom-left large purple object blue', shape=(), dtype=string)\", \"tf.Tensor(b'make middle-right rectangle large', shape=(), dtype=string)\", \"tf.Tensor(b'remove middle-right small green object', shape=(), dtype=string)\", \"tf.Tensor(b'add green rectangle to top-right', shape=(), dtype=string)\", \"tf.Tensor(b'make middle-left large brown object red', shape=(), dtype=string)\", \"tf.Tensor(b'make top-center circle large', shape=(), dtype=string)\", \"tf.Tensor(b'add large green rectangle to bottom-right', shape=(), dtype=string)\", \"tf.Tensor(b'remove top-left small green circle', shape=(), dtype=string)\", \"tf.Tensor(b'remove top-right red triangle', shape=(), dtype=string)\", \"tf.Tensor(b'make bottom-center gray object small', shape=(), dtype=string)\", \"tf.Tensor(b'make bottom-left small cyan object purple', shape=(), dtype=string)\", \"tf.Tensor(b'make bottom-left blue rectangle yellow', shape=(), dtype=string)\", \"tf.Tensor(b'make top-right object cyan', shape=(), dtype=string)\", \"tf.Tensor(b'add small green circle', shape=(), dtype=string)\", \"tf.Tensor(b'make top-center small gray rectangle yellow', shape=(), dtype=string)\", \"tf.Tensor(b'make bottom-center small gray rectangle blue', shape=(), dtype=string)\", \"tf.Tensor(b'make top-left yellow rectangle green', shape=(), dtype=string)\", \"tf.Tensor(b'make bottom-right large brown object red', shape=(), dtype=string)\", \"tf.Tensor(b'make middle-left large blue rectangle small', shape=(), dtype=string)\", \"tf.Tensor(b'make middle-left cyan object purple', shape=(), dtype=string)\", \"tf.Tensor(b'add small red triangle to bottom-right', shape=(), dtype=string)\", \"tf.Tensor(b'make bottom-center large triangle blue', shape=(), dtype=string)\", \"tf.Tensor(b'make middle-left large cyan object green', shape=(), dtype=string)\", \"tf.Tensor(b'add large blue circle to top-right', shape=(), dtype=string)\", \"tf.Tensor(b'make large red circle gray', shape=(), dtype=string)\", \"tf.Tensor(b'make top-left small triangle gray', shape=(), dtype=string)\"]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _th_index_select",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-d086743d037e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model.compute_loss(torch.from_numpy(x['source'].numpy()).permute(0,3,1,2),\n\u001b[0;32m----> 2\u001b[0;31m                    [str(t) for t in x['mod_str']],x['target'],soft_triplet_loss=True)\n\u001b[0m",
      "\u001b[0;32m~/alin/project/Image_text_retrival/img_text_composition_models.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, imgs_query, modification_texts, imgs_target, soft_triplet_loss)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimgs_query\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodification_texts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimgs_target\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msoft_triplet_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m             \u001b[0mmod_img1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompose_img_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodification_texts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m             \u001b[0mmod_img1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalization_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod_img1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mimg2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_img_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/alin/project/Image_text_retrival/img_text_composition_models.py\u001b[0m in \u001b[0;36mcompose_img_text\u001b[0;34m(self, imgs, texts)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompose_img_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0mimg_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_img_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         \u001b[0mtext_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_text_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompose_img_text_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/alin/project/Image_text_retrival/img_text_composition_models.py\u001b[0m in \u001b[0;36mextract_text_feature\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextract_text_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m              \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgs_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodification_texts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrl_lambda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/alin/project/Image_text_retrival/text_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_encoded_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward_encoded_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/alin/project/Image_text_retrival/text_model.py\u001b[0m in \u001b[0;36mforward_encoded_texts\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m     \u001b[0metexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# lstm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m         return F.embedding(\n\u001b[1;32m    113\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _th_index_select"
     ]
    }
   ],
   "source": [
    "model.compute_loss(torch.from_numpy(x['source'].numpy()).permute(0,3,1,2),\n",
    "                   [str(t) for t in x['mod_str']],x['target'],soft_triplet_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_batch_based_classification_loss_(mod_img1, img2):\n",
    "    x = torch.matmul(torch.tensor(mod_img1), torch.tensor(img2.transpose(1, 0)))\n",
    "    labels = torch.tensor(range(x.shape[0])).long()\n",
    "    labels = torch.autograd.Variable(labels)\n",
    "    return torch.nn.functional.cross_entropy(x, labels).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss2(mod_img1, img2):\n",
    "    x=tf.matmul(mod_img1, tf.transpose(img2, perm=[ 1, 0]))\n",
    "    labels = (range(x.shape[0]))\n",
    "    return tf.reduce_sum(tf.nn.sparse_softmax_cross_entropy_with_logits(labels, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TIRGmodel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-dfba232a6234>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimgT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#                 print(text_features.shape,imgS.shape,imgT.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mC_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTIRGmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_soft_triplet_loss_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimgT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TIRGmodel' is not defined"
     ]
    }
   ],
   "source": [
    "text_features=text_model(x['mod_str'])\n",
    "imgS=img_extractor(x['source'])\n",
    "imgT=img_extractor(x['target'])\n",
    "#                 print(text_features.shape,imgS.shape,imgT.shape)\n",
    "C_feature=TIRGmodel(text_features, imgS)\n",
    "loss=compute_soft_triplet_loss_(C_feature,imgT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(compute_batch_based_classification_loss_(C_feature.numpy(), imgT.numpy()))\n",
    "print(compute_batch_based_classification_loss_(imgS.numpy(), imgT.numpy()))\n",
    "print(compute_batch_based_classification_loss_(imgT.numpy(), imgT.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(loss2(C_feature.numpy(), imgT.numpy()))\n",
    "print(loss2(imgS.numpy(), imgT.numpy()))\n",
    "print(loss2(imgT.numpy(), imgT.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# my_seq2(x['source'])-my_seq2(x['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_soft_triplet_loss_( mod_img1, img2):\n",
    "    triplets = []\n",
    "    labels = list(range(mod_img1.shape[0])) + list(range(img2.shape[0]))\n",
    "    for i in range(len(labels)):\n",
    "      triplets_i = []\n",
    "      for j in range(len(labels)):\n",
    "        if labels[i] == labels[j] and i != j:\n",
    "          for k in range(len(labels)):\n",
    "            if labels[i] != labels[k]:\n",
    "              triplets_i.append([i, j, k])\n",
    "      np.random.shuffle(triplets_i)\n",
    "      triplets += triplets_i[:3]\n",
    "    assert (triplets and len(triplets) < 2000)\n",
    "    #print(self.soft_triplet_loss(torch.cat([mod_img1, img2]), triplets))\n",
    "    soft_triplet_loss=TripletLoss()\n",
    "    return soft_triplet_loss(tf.concat([mod_img1, img2], axis= 0, name='concat'), triplets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pairwise_distances(x, y=None):\n",
    "  \"\"\"\n",
    "    Input: x is a Nxd matrix\n",
    "           y is an optional Mxd matirx\n",
    "    Output: dist is a NxM matrix where dist[i,j] is the square norm between\n",
    "    x[i,:] and y[j,:]\n",
    "            if y is not given then use 'y=x'.\n",
    "    i.e. dist[i,j] = ||x[i,:]-y[j,:]||^2\n",
    "    source:\n",
    "    https://discuss.pytorch.org/t/efficient-distance-matrix-computation/9065/2\n",
    "    \"\"\"\n",
    "  x_norm1 = torch.from_numpy((x**2).numpy()).sum(1).view(-1, 1)\n",
    "  #print(x_norm1)\n",
    "  x_norm = tf.reshape(tf.reduce_sum(x**2,1), [-1, 1])\n",
    "  #print(x_norm1.numpy()-x_norm)\n",
    "  if y is not None:\n",
    "        y_t = tf.transpose(y, perm=[ 1, 0])\n",
    "        y_norm = tf.reshape(tf.reduce_sum(y**2,1), [-1, 1])\n",
    "        #print(\"y\",y_t.shape)\n",
    "  else:\n",
    "    y_t = tf.transpose(x,  perm=[1, 0]) \n",
    "    y_norm = tf.reshape(x_norm,[1,-1])\n",
    "    \n",
    "    y_t1 = torch.transpose(torch.from_numpy(x.numpy()), 0, 1)\n",
    "    y_norm1 =( x_norm1).view(1, -1)\n",
    "    #print(np.sum(y_norm-y_norm1.numpy()))\n",
    "\n",
    "  dist = x_norm + y_norm \n",
    "  dist = dist - 2.0 * tf.matmul(x, y_t)\n",
    "    \n",
    "  dist1= x_norm1 + y_norm1 - 2.0 * torch.mm(torch.from_numpy(x.numpy()), y_t1)\n",
    "  #print(\"torch clam\",torch.clamp(dist1, 0.0, np.inf)) \n",
    "  #print(\"TENSORFLO\",tf.clip_by_value(dist, clip_value_min= 0.0, clip_value_max=1000) )\n",
    "  \n",
    "  # Ensure diagonal is zero if x=y\n",
    "  # if y is None:\n",
    "  #     dist = dist - torch.diag(dist.diag)\n",
    "  return dist1\n",
    "class TripletLoss(tf.keras.Model):\n",
    "  \"\"\"Class for the triplet loss.\"\"\"\n",
    "  def __init__(self, pre_layer=None):\n",
    "    super(TripletLoss, self).__init__()\n",
    "    self.pre_layer = pre_layer\n",
    "\n",
    "  def call(self, x, triplets):\n",
    "    \n",
    "    if self.pre_layer is not None:\n",
    "      x = self.pre_layer(x)\n",
    "    \n",
    "    \n",
    "    #loss = MyTripletLossFunc(triplets)(x)\n",
    "\n",
    "    #modifications\n",
    "    self.triplets = triplets\n",
    "    #print(triplets)\n",
    "    self.triplet_count = len(triplets)\n",
    "    #self.distances = pairwise_distances(x).detach().cpu().numpy()\n",
    "    self.distances = pairwise_distances(x)\n",
    "    #print(np.max(self.distances) )\n",
    "    loss = 0.0\n",
    "    triplet_count = 0.0\n",
    "    correct_count = 0.0\n",
    "    max_loss=0\n",
    "    for i, j, k in self.triplets:\n",
    "      w = 1.0\n",
    "      triplet_count += w\n",
    "      loss += w * np.log(1 +np.exp(self.distances[i, j] - self.distances[i, k]))\n",
    "#       if (np.log(1 +np.exp(self.distances[i, j] - self.distances[i, k]))>10000):\n",
    "#             #print(self.distances[i, j] , self.distances[i, k],\"NEXT\")\n",
    "   \n",
    "      if self.distances[i, j] < self.distances[i, k]:\n",
    "        correct_count += 1\n",
    "    #print(triplet_count)\n",
    "    loss /= triplet_count\n",
    "    #print(loss)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_features=text_model(x['mod_str'])\n",
    "imgS=img_extractor(x['source'])\n",
    "imgT=img_extractor(x['target'])\n",
    "#                 print(text_features.shape,imgS.shape,imgT.shape)\n",
    "C_feature=TIRGmodel(text_features, imgS)\n",
    "print(compute_soft_triplet_loss_(C_feature,imgT))\n",
    "print(compute_soft_triplet_loss_(imgT,imgS))\n",
    "print(compute_soft_triplet_loss_(imgT,imgT))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(imgS-imgT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_plot = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# img_model = ResnetIdentityBlock()\n",
    "# text_model = TextLSTMModel(\n",
    "#                     texts_to_build_vocab=texts,\n",
    "#                     word_embed_dim=embed_dim,\n",
    "#                     lstm_hidden_dim=embed_dim)\n",
    "# compose=Composer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# t_img=my_seq2(x['target'])\n",
    "# print(s_img.shape)\n",
    "# s_img=my_seq2(x['source'])\n",
    "# print(t_img.shape)\n",
    "# text_features=text_model.forward_encoded_texts(x['mod_str'])\n",
    "# C_feature=compose(s_img, text_features)\n",
    "\n",
    "\n",
    "# compute_soft_triplet_loss_(C_feature,s_img)\n",
    "#loss2(C_feature,t_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_model = TextLSTMModel(\n",
    "                    texts_to_build_vocab=texts,\n",
    "                    word_embed_dim=embed_dim,\n",
    "                    lstm_hidden_dim=embed_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMG_SHAPE = (224, 224, 3)\n",
    "base_model =tf.keras.applications.ResNet50(\n",
    "    include_top=False, weights='imagenet', input_shape=IMG_SHAPE)\n",
    "base_model.trainable = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_model=tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mobilenetv2_1.00_224\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_pad (ZeroPadding2D)       (None, 225, 225, 3)  0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Conv1 (Conv2D)                  (None, 112, 112, 32) 864         Conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_Conv1 (BatchNormalization)   (None, 112, 112, 32) 128         Conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_relu (ReLU)               (None, 112, 112, 32) 0           bn_Conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise (Depthw (None, 112, 112, 32) 288         Conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_BN (Bat (None, 112, 112, 32) 128         expanded_conv_depthwise[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_relu (R (None, 112, 112, 32) 0           expanded_conv_depthwise_BN[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project (Conv2D)  (None, 112, 112, 16) 512         expanded_conv_depthwise_relu[0][0\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project_BN (Batch (None, 112, 112, 16) 64          expanded_conv_project[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand (Conv2D)         (None, 112, 112, 96) 1536        expanded_conv_project_BN[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_BN (BatchNormali (None, 112, 112, 96) 384         block_1_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_relu (ReLU)      (None, 112, 112, 96) 0           block_1_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_pad (ZeroPadding2D)     (None, 113, 113, 96) 0           block_1_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise (DepthwiseCon (None, 56, 56, 96)   864         block_1_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_BN (BatchNorm (None, 56, 56, 96)   384         block_1_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_relu (ReLU)   (None, 56, 56, 96)   0           block_1_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project (Conv2D)        (None, 56, 56, 24)   2304        block_1_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project_BN (BatchNormal (None, 56, 56, 24)   96          block_1_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand (Conv2D)         (None, 56, 56, 144)  3456        block_1_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_BN (BatchNormali (None, 56, 56, 144)  576         block_2_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_relu (ReLU)      (None, 56, 56, 144)  0           block_2_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise (DepthwiseCon (None, 56, 56, 144)  1296        block_2_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_BN (BatchNorm (None, 56, 56, 144)  576         block_2_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_relu (ReLU)   (None, 56, 56, 144)  0           block_2_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project (Conv2D)        (None, 56, 56, 24)   3456        block_2_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project_BN (BatchNormal (None, 56, 56, 24)   96          block_2_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_add (Add)               (None, 56, 56, 24)   0           block_1_project_BN[0][0]         \n",
      "                                                                 block_2_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand (Conv2D)         (None, 56, 56, 144)  3456        block_2_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_BN (BatchNormali (None, 56, 56, 144)  576         block_3_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_relu (ReLU)      (None, 56, 56, 144)  0           block_3_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_pad (ZeroPadding2D)     (None, 57, 57, 144)  0           block_3_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise (DepthwiseCon (None, 28, 28, 144)  1296        block_3_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_BN (BatchNorm (None, 28, 28, 144)  576         block_3_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_relu (ReLU)   (None, 28, 28, 144)  0           block_3_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project (Conv2D)        (None, 28, 28, 32)   4608        block_3_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project_BN (BatchNormal (None, 28, 28, 32)   128         block_3_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand (Conv2D)         (None, 28, 28, 192)  6144        block_3_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_4_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_4_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise (DepthwiseCon (None, 28, 28, 192)  1728        block_4_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_BN (BatchNorm (None, 28, 28, 192)  768         block_4_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_relu (ReLU)   (None, 28, 28, 192)  0           block_4_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project (Conv2D)        (None, 28, 28, 32)   6144        block_4_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project_BN (BatchNormal (None, 28, 28, 32)   128         block_4_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_add (Add)               (None, 28, 28, 32)   0           block_3_project_BN[0][0]         \n",
      "                                                                 block_4_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand (Conv2D)         (None, 28, 28, 192)  6144        block_4_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_5_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_5_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise (DepthwiseCon (None, 28, 28, 192)  1728        block_5_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_BN (BatchNorm (None, 28, 28, 192)  768         block_5_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_relu (ReLU)   (None, 28, 28, 192)  0           block_5_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project (Conv2D)        (None, 28, 28, 32)   6144        block_5_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project_BN (BatchNormal (None, 28, 28, 32)   128         block_5_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_5_add (Add)               (None, 28, 28, 32)   0           block_4_add[0][0]                \n",
      "                                                                 block_5_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand (Conv2D)         (None, 28, 28, 192)  6144        block_5_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_6_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_6_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_pad (ZeroPadding2D)     (None, 29, 29, 192)  0           block_6_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise (DepthwiseCon (None, 14, 14, 192)  1728        block_6_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_BN (BatchNorm (None, 14, 14, 192)  768         block_6_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_relu (ReLU)   (None, 14, 14, 192)  0           block_6_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project (Conv2D)        (None, 14, 14, 64)   12288       block_6_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project_BN (BatchNormal (None, 14, 14, 64)   256         block_6_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand (Conv2D)         (None, 14, 14, 384)  24576       block_6_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_7_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_7_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_7_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_7_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_7_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project (Conv2D)        (None, 14, 14, 64)   24576       block_7_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project_BN (BatchNormal (None, 14, 14, 64)   256         block_7_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_add (Add)               (None, 14, 14, 64)   0           block_6_project_BN[0][0]         \n",
      "                                                                 block_7_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand (Conv2D)         (None, 14, 14, 384)  24576       block_7_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_8_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_8_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_8_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_8_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_8_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project (Conv2D)        (None, 14, 14, 64)   24576       block_8_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project_BN (BatchNormal (None, 14, 14, 64)   256         block_8_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_8_add (Add)               (None, 14, 14, 64)   0           block_7_add[0][0]                \n",
      "                                                                 block_8_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand (Conv2D)         (None, 14, 14, 384)  24576       block_8_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_9_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_9_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_9_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_9_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_9_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project (Conv2D)        (None, 14, 14, 64)   24576       block_9_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project_BN (BatchNormal (None, 14, 14, 64)   256         block_9_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_9_add (Add)               (None, 14, 14, 64)   0           block_8_add[0][0]                \n",
      "                                                                 block_9_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand (Conv2D)        (None, 14, 14, 384)  24576       block_9_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_BN (BatchNormal (None, 14, 14, 384)  1536        block_10_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_relu (ReLU)     (None, 14, 14, 384)  0           block_10_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise (DepthwiseCo (None, 14, 14, 384)  3456        block_10_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_BN (BatchNor (None, 14, 14, 384)  1536        block_10_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           block_10_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project (Conv2D)       (None, 14, 14, 96)   36864       block_10_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project_BN (BatchNorma (None, 14, 14, 96)   384         block_10_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand (Conv2D)        (None, 14, 14, 576)  55296       block_10_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_11_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_11_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_11_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_11_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_relu (ReLU)  (None, 14, 14, 576)  0           block_11_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project (Conv2D)       (None, 14, 14, 96)   55296       block_11_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project_BN (BatchNorma (None, 14, 14, 96)   384         block_11_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_add (Add)              (None, 14, 14, 96)   0           block_10_project_BN[0][0]        \n",
      "                                                                 block_11_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand (Conv2D)        (None, 14, 14, 576)  55296       block_11_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_12_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_12_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_12_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_12_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_relu (ReLU)  (None, 14, 14, 576)  0           block_12_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project (Conv2D)       (None, 14, 14, 96)   55296       block_12_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project_BN (BatchNorma (None, 14, 14, 96)   384         block_12_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_12_add (Add)              (None, 14, 14, 96)   0           block_11_add[0][0]               \n",
      "                                                                 block_12_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand (Conv2D)        (None, 14, 14, 576)  55296       block_12_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_13_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_13_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_pad (ZeroPadding2D)    (None, 15, 15, 576)  0           block_13_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise (DepthwiseCo (None, 7, 7, 576)    5184        block_13_pad[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_BN (BatchNor (None, 7, 7, 576)    2304        block_13_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_relu (ReLU)  (None, 7, 7, 576)    0           block_13_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project (Conv2D)       (None, 7, 7, 160)    92160       block_13_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project_BN (BatchNorma (None, 7, 7, 160)    640         block_13_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand (Conv2D)        (None, 7, 7, 960)    153600      block_13_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_14_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_14_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_14_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_14_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_14_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project (Conv2D)       (None, 7, 7, 160)    153600      block_14_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project_BN (BatchNorma (None, 7, 7, 160)    640         block_14_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_add (Add)              (None, 7, 7, 160)    0           block_13_project_BN[0][0]        \n",
      "                                                                 block_14_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand (Conv2D)        (None, 7, 7, 960)    153600      block_14_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_15_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_15_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_15_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_15_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_15_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project (Conv2D)       (None, 7, 7, 160)    153600      block_15_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project_BN (BatchNorma (None, 7, 7, 160)    640         block_15_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_15_add (Add)              (None, 7, 7, 160)    0           block_14_add[0][0]               \n",
      "                                                                 block_15_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand (Conv2D)        (None, 7, 7, 960)    153600      block_15_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_16_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_16_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_16_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_16_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_16_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project (Conv2D)       (None, 7, 7, 320)    307200      block_16_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project_BN (BatchNorma (None, 7, 7, 320)    1280        block_16_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1 (Conv2D)                 (None, 7, 7, 1280)   409600      block_16_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1_bn (BatchNormalization)  (None, 7, 7, 1280)   5120        Conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "out_relu (ReLU)                 (None, 7, 7, 1280)   0           Conv_1_bn[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,257,984\n",
      "Trainable params: 2,223,872\n",
      "Non-trainable params: 34,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers in the base model:  155\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of layers in the base model: \", len(base_model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers in the base model:  155\n"
     ]
    }
   ],
   "source": [
    "# Let's take a look to see how many layers are in the base model\n",
    "print(\"Number of layers in the base model: \", len(base_model.layers))\n",
    "base_model.trainable = True\n",
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 0\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "      layer.trainable =  False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenetv2_1.00_224 (Model) (None, 7, 7, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_1 (Glob (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 1280)              5120      \n",
      "=================================================================\n",
      "Total params: 2,263,104\n",
      "Trainable params: 2,226,432\n",
      "Non-trainable params: 36,672\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "img_extractor = tf.keras.Sequential([\n",
    "  base_model,\n",
    "  tf.keras.layers.GlobalMaxPooling2D(data_format=None),\n",
    "  tf.keras.layers.BatchNormalization()\n",
    "])\n",
    "img_extractor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TIRGmodel=TIRG(texts,1280)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer1 = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
    "optimizer2 = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "optimizer3 = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "def train_step(x):\n",
    "        loss = 0\n",
    "        with tf.GradientTape() as tape1, tf.GradientTape() as tape2, tf.GradientTape() as tape3:\n",
    "#                 print(x['source'].shape,x['target'].shape)\n",
    "                text_features=text_model(x['mod_str'])\n",
    "                imgS=img_extractor(x['source'])\n",
    "                imgT=img_extractor(x['target'])\n",
    "                #print(text_features.shape,imgS.shape,imgT.shape)\n",
    "                C_feature=TIRGmodel(text_features, imgS)\n",
    "                loss=loss2(C_feature,imgT)\n",
    "                #loss=loss+loss2(imgT,imgT)\n",
    "                #print(loss)\n",
    "\n",
    "#         trainable_variables1 = img_extractor.trainable_variables \n",
    "#         trainable_variables2 = TIRGmodel.trainable_variables\n",
    "#         trainable_variables3 = text_model.trainable_variables\n",
    "\n",
    "        gradients_of_generator = tape1.gradient(loss,TIRGmodel.trainable_variables) \n",
    "        optimizer2.apply_gradients(zip(gradients_of_generator, TIRGmodel.trainable_variables))\n",
    "        \n",
    "        gradients_of_d = tape2.gradient(loss,text_model.trainable_variables) \n",
    "        optimizer3.apply_gradients(zip(gradients_of_d, text_model.trainable_variables))\n",
    "        \n",
    "        gradients_of_d = tape3.gradient(loss,img_extractor.trainable_variables) \n",
    "        optimizer1.apply_gradients(zip(gradients_of_d, img_extractor.trainable_variables))\n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "        #optimizer1.apply_gradients(zip(D1, trainable_variables1))\n",
    "        #optimizer2.apply_gradients(zip(D2, trainable_variables2))\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[32,56,56,96] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:DepthwiseConv2dNative] name: sequential_12/mobilenetv2_1.00_224/block_1_depthwise/depthwise/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-bd1987d68997>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mt_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mbatchloss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mt_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mt_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-81-2105672da180>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#                 print(x['source'].shape,x['target'].shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                 \u001b[0mtext_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mod_str'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                 \u001b[0mimgS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'source'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m                 \u001b[0mimgT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0;31m#print(text_features.shape,imgS.shape,imgT.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    821\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 822\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow_core/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    265\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m  \u001b[0;31m# handle the corner case where self.layers is empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    715\u001b[0m     return self._run_internal_graph(\n\u001b[1;32m    716\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m           \u001b[0;31m# Compute outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m           \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    821\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 822\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    715\u001b[0m     return self._run_internal_graph(\n\u001b[1;32m    716\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m           \u001b[0;31m# Compute outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m           \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    821\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 822\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow_core/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1844\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1845\u001b[0m         \u001b[0mdilation_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1846\u001b[0;31m         data_format=self.data_format)\n\u001b[0m\u001b[1;32m   1847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1848\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36mdepthwise_conv2d\u001b[0;34m(x, depthwise_kernel, strides, padding, data_format, dilation_rate)\u001b[0m\n\u001b[1;32m   5133\u001b[0m       \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5134\u001b[0m       \u001b[0mrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilation_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5135\u001b[0;31m       data_format=tf_data_format)\n\u001b[0m\u001b[1;32m   5136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'channels_first'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtf_data_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'NHWC'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5137\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# NHWC -> NCHW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow_core/python/ops/nn_impl.py\u001b[0m in \u001b[0;36mdepthwise_conv2d\u001b[0;34m(input, filter, strides, padding, rate, name, data_format, dilations)\u001b[0m\n\u001b[1;32m    816\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         op=op)\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow_core/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mwith_space_to_batch\u001b[0;34m(input, dilation_rate, padding, op, filter_shape, spatial_dims, data_format)\u001b[0m\n\u001b[1;32m    482\u001b[0m       \u001b[0mspatial_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspatial_dims\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m       data_format=data_format)\n\u001b[0;32m--> 484\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnew_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow_core/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inp, filter)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow_core/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(inp, _)\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbuild_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_spatial_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_spatial_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m   new_op = _WithSpaceToBatch(\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow_core/python/ops/nn_impl.py\u001b[0m in \u001b[0;36mop\u001b[0;34m(input_converted, _, padding)\u001b[0m\n\u001b[1;32m    808\u001b[0m           \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m           \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m           name=name)\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m     return nn_ops.with_space_to_batch(\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow_core/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mdepthwise_conv2d_native\u001b[0;34m(input, filter, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   2184\u001b[0m         \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2185\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2186\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2187\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2188\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6604\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6605\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6606\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6607\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[32,56,56,96] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:DepthwiseConv2dNative] name: sequential_12/mobilenetv2_1.00_224/block_1_depthwise/depthwise/"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "num_steps=19000\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    total_loss = 0\n",
    "    batchloss = 0\n",
    "    print(\"Epoch\",epoch,)\n",
    "    for (batch, x) in enumerate(image_dataset):\n",
    "        t_loss = train_step(x)\n",
    "        batchloss+=t_loss\n",
    "        total_loss += t_loss\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "#             print(t_loss)\n",
    "            print ('Epoch {} Batch {}'.format(\n",
    "              epoch + 1, batch))\n",
    "            print(batchloss)\n",
    "            batchloss=0\n",
    "    # storing the epoch end loss value to plot later\n",
    "    loss_plot.append(total_loss / num_steps)\n",
    "    if epoch%5==1:\n",
    "        tests = []\n",
    "        for name, dataset in [ ('test', testset)]:\n",
    "            t = test(opt, TIRGmodel,img_extractor,text_model, dataset)\n",
    "            tests += [(name + ' ' + metric_name, metric_value)\n",
    "                      for metric_name, metric_value in t]\n",
    "        for metric_name, metric_value in tests:\n",
    "            print ('    ', metric_name, round(metric_value, 4))\n",
    "            \n",
    "    print ('Epoch {} Loss {:.6f}'.format(epoch + 1,\n",
    "                                         total_loss/num_steps))\n",
    "    print ('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "num_steps=19000\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    total_loss = 0\n",
    "    batchloss = 0\n",
    "    print(\"Epoch\",epoch,)\n",
    "    for (batch, x) in enumerate(image_dataset):\n",
    "        t_loss = train_step(x)\n",
    "        batchloss+=t_loss\n",
    "        total_loss += t_loss\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "#             print(t_loss)\n",
    "            print ('Epoch {} Batch {}'.format(\n",
    "              epoch + 1, batch))\n",
    "            print(batchloss)\n",
    "            batchloss=0\n",
    "    # storing the epoch end loss value to plot later\n",
    "    loss_plot.append(total_loss / num_steps)\n",
    "    if epoch%5==1:\n",
    "        tests = []\n",
    "        for name, dataset in [ ('test', testset)]:\n",
    "            t = test(opt, TIRGmodel,img_extractor,text_model, dataset)\n",
    "            tests += [(name + ' ' + metric_name, metric_value)\n",
    "                      for metric_name, metric_value in t]\n",
    "        for metric_name, metric_value in tests:\n",
    "            print ('    ', metric_name, round(metric_value, 4))\n",
    "            \n",
    "    print ('Epoch {} Loss {:.6f}'.format(epoch + 1,\n",
    "                                         total_loss/num_steps))\n",
    "    print ('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(loss_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_plot=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TIRGmodel.save_weights('/home/alinsteinjose/alin/project/Image_text_retrival/Tensorflow_TIRG_model')\n",
    "text_model.save_weights('/home/alinsteinjose/alin/project/Image_text_retrival/Tensorflow_TXT_model')\n",
    "img_extractor.save_weights('/home/alinsteinjose/alin/project/Image_text_retrival/Tensorflow_IMG_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a new model instance\n",
    "model = create_model()\n",
    "\n",
    "# Restore the weights\n",
    "model.load_weights('./checkpoints/my_checkpoint')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
